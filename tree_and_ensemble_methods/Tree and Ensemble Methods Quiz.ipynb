{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b872ea38",
   "metadata": {},
   "source": [
    "<h1>Tree and Ensemble Methods Quiz</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee26b29",
   "metadata": {},
   "source": [
    "<h3>Decision Trees</h3>\n",
    "\n",
    "<p>Decision trees cannot be used for regression problems.\n",
    "    \n",
    "Answer: False</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02d644",
   "metadata": {},
   "source": [
    "<h3>Decision Tree Splitting</h3>\n",
    "\n",
    "<p>Which of the following is / are correct? When we construct a decision tree, we split the features based on the:\n",
    "\n",
    "Answer: gini coefficient, information gain</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac47124",
   "metadata": {},
   "source": [
    "<h3>Categorical Data</h3>\n",
    "\n",
    "<p>In real-life scenarios, your data will consist of real-valued (i.e. numerical) variables and categorical variables. Suppose you convert the categorical variables to integers (0, 1, 2, etc.). Which of the algorithms will work correctly with the categorical variables, without additional settings?\n",
    "    \n",
    "Answer: AdaBoost\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05cebc",
   "metadata": {},
   "source": [
    "<h3>Performance</h3>\n",
    "\n",
    "<p>You want to perform model selection on a random forest classifier. To do this, you perform grid search on two parameters: number of trees (k): 100, 200, 300; learning rate (alpha): 0.01, 1, 10. Which parameter will not influence the running time of the training during cross-validation? Write \"k\" or \"alpha\".\n",
    "    \n",
    "Answer: k</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb258f1",
   "metadata": {},
   "source": [
    "<h3>Metrics</h3>\n",
    "\n",
    "<p>You want to train a random forest to classify images of cancerous cells (positive, class 1) vs. healthy cells (negative, class 0). In your dataset, you have 50 000 samples in total, 5000 of which are positive. Which measure is the most accurate to measure the performance of a model using AdaBoost? Note that while all measures will give somewhat valid results, there is only one correct answer.\n",
    "\n",
    "Answer: accuracy</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854bee7",
   "metadata": {},
   "source": [
    "<h3>More Data</h3>\n",
    "\n",
    "<p>You want to train a decision forest to classify images of cats and dogs. There are approximately the same number of pictures of cats and dogs in your dataset. You fix all parameters (500 trees, depth = 5) and don't perform any hyperparameter tuning. You train an algorithm on 30% of the data, and another algorithm - on 80%. Which algorithm is more likely to overfit?\n",
    "\n",
    "Answer: first (30% of the train data)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506ab5e",
   "metadata": {},
   "source": [
    "<h3>Bagging Classifier</h3>\n",
    "\n",
    "<p>Suppose you want to use a BaggingClassifier to train a model. This classifier works similarly to AdaBoost. You can look at the docs for more information. You want to combine 100 estimators. Each individual estimator has approximately 60% accuracy. What is the minimum accuracy that you will get using the BaggingClassifier?\n",
    "\n",
    "Answer: >60%</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
